{
 "metadata": {
  "name": "",
  "signature": "sha256:c293e1dda8a62a5b6aa7664ebf79239e6775a6d954eda835dc9398e9a7d08e2b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fields = ['features', 'processed_urls']\n",
      "\n",
      "import h5py\n",
      "with h5py.File('flickr_20k_features.hdf5') as f:\n",
      "    data = {field: f[field].value for field in fields}\n",
      "\n",
      "print data['processed_urls'][:4]\n",
      "print data['features'][:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['http://farm2.staticflickr.com/1227/5159730964_124c1e63d8.jpg'\n",
        " 'http://farm9.staticflickr.com/8368/8530766395_4229f47bf4.jpg'\n",
        " 'http://farm3.staticflickr.com/2875/13297737684_11aeeda27a.jpg'\n",
        " 'http://farm8.staticflickr.com/7218/13293240683_069fd4cca5.jpg']\n",
        "[[ 0.          0.          0.         ...,  0.23254371  0.          0.        ]\n",
        " [ 0.          0.25537062  0.         ...,  0.          0.          0.        ]\n",
        " [ 0.          0.          0.         ...,  1.15372443  0.          0.        ]\n",
        " [ 0.          0.          0.         ...,  1.79112899  0.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "pca = PCA(n_components=15)\n",
      "%time reduced_features = pca.fit_transform(data['features'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4min 54s, sys: 4.15 s, total: 4min 58s\n",
        "Wall time: 3min 40s\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot cosine similarity of 2 images\n",
      "import random\n",
      "from scipy.spatial.distance import cosine\n",
      "\n",
      "similar_images = [0, ]\n",
      "random_pair = [0, random.randint(0, data['features'].shape[0])]\n",
      "\n",
      "def distance(pair):\n",
      "    return cosine(femto_features[pair[0]], femto_features[pair[1]])\n",
      "\n",
      "print distance(similar_images), distance(random_pair)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import skimage.io\n",
      "from scipy.ndimage import zoom\n",
      "\n",
      "def center_crop_image(url):\n",
      "    \"\"\"\n",
      "    Scale and center-crop the images, so they appear as the neural network sees them\n",
      "    \"\"\"\n",
      "    image = skimage.io.imread(url)\n",
      "    \n",
      "    # intepret greyscale images as RGB\n",
      "    if image.ndim == 2:\n",
      "        image = image[:, :, np.newaxis]\n",
      "        image = np.tile(image, (1, 1, 3))\n",
      "    \n",
      "    # resize the image\n",
      "    input_image_dimensions = np.array([227, 227])\n",
      "    scale = input_image_dimensions[0].astype('float32') / np.array(image.shape)[:2]\n",
      "    \n",
      "    # scale up or down in size?\n",
      "    if scale.min() <= input_image_dimensions.min():\n",
      "        zoom_factor = scale.max()\n",
      "    else:\n",
      "        zoom_factor = scale.min()\n",
      "    \n",
      "    resized_image = zoom(image, (zoom_factor, zoom_factor, 1), order=1)\n",
      "    \n",
      "    # centre crop the image\n",
      "    center = np.array(resized_image.shape[:2]) / 2.0\n",
      "    crop = np.tile(center, (1, 2))[0] + np.concatenate([-input_image_dimensions / 2.0, input_image_dimensions / 2.0])\n",
      "    center_cropped_image = resized_image[crop[0]:crop[2], crop[1]:crop[3], :]\n",
      "    return center_cropped_image\n",
      "\n",
      "\n",
      "def plot_image_pairs(pair, figure_title=\"\"):\n",
      "    images = [center_crop_image(data['processed_urls'][i] for i in pair)]\n",
      "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
      "    fig.suptitle(figure_title, fontsize=30)\n",
      "    for index, image_index in enumerate(pair):\n",
      "        axes[0, index].xaxis.set_visible(False)\n",
      "        axes[0, index].yaxis.set_visible(False)\n",
      "        axes[0, index].imshow(images[index])\n",
      "\n",
      "plot_image_pairs(similar_images, \"Distance: {0}\".format(distance(similar_images)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_image_pairs(random_pair, \"Distance: {0}\".format(distance(random_pair)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```docker pull docker/elasticsearch```\n",
      "```docker run -d -p 9200:9200 -p 9300:9300 dockerfile/elasticsearch```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bulk_data = []\n",
      "for index in xrange(reduced_features.shape[0]):\n",
      "    document_metadata = {'index': {'_index': 'images', '_type': 'features', '_id': index}}\n",
      "    \n",
      "    document = dict(**{\"feature_{0}\".format(i): str(reduced_features[index][i]) for i in xrange(reduced_features.shape[1])})\n",
      "    document['url'] = data['processed_urls'][index]\n",
      "    document['id'] = index + 1\n",
      "\n",
      "    bulk_data.append(document_metadata)\n",
      "    bulk_data.append(document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from elasticsearch import Elasticsearch\n",
      "\n",
      "es = Elasticsearch(hosts=[{'host': '192.168.59.103', 'port': 9200}])  # on a mac use `boot2docker ip` rather than localhost\n",
      "\n",
      "# define a mapping to ensure the features are stored in the index\n",
      "# mapping = {'features': {\n",
      "#         'properties': {\n",
      "#             'url': {'type': 'string'},\n",
      "#             'id': {'type': 'integer'}\n",
      "#         }\n",
      "#     }\n",
      "# }\n",
      "# for i in xrange(reduced_features.shape[1]):\n",
      "#     mapping['features']['properties']['feature_' + str(i)] = {'type': 'string', 'store': True}\n",
      "    \n",
      "# es.indices.create(index='images')\n",
      "# es.indices.put_mapping(index='images', doc_type='features', body=mapping)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "{u'acknowledged': True}"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = es.bulk(index='images', body=bulk_data, refresh=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "es.search(index='images', doc_type='features', size=2, body={\"query\": {\"term\": {'id': 1}}})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "{u'_shards': {u'failed': 0, u'successful': 5, u'total': 5},\n",
        " u'hits': {u'hits': [{u'_id': u'0',\n",
        "    u'_index': u'images',\n",
        "    u'_score': 1.0,\n",
        "    u'_source': {u'feature_0': u'-12.4171',\n",
        "     u'feature_1': u'5.83133',\n",
        "     u'feature_10': u'2.54454',\n",
        "     u'feature_11': u'14.8686',\n",
        "     u'feature_12': u'-6.63789',\n",
        "     u'feature_13': u'-9.20783',\n",
        "     u'feature_14': u'-12.3993',\n",
        "     u'feature_2': u'-6.59257',\n",
        "     u'feature_3': u'8.9641',\n",
        "     u'feature_4': u'10.3449',\n",
        "     u'feature_5': u'0.966538',\n",
        "     u'feature_6': u'6.04452',\n",
        "     u'feature_7': u'3.87064',\n",
        "     u'feature_8': u'3.10364',\n",
        "     u'feature_9': u'-0.862942',\n",
        "     u'id': 1,\n",
        "     u'url': u'http://farm2.staticflickr.com/1227/5159730964_124c1e63d8.jpg'},\n",
        "    u'_type': u'features'}],\n",
        "  u'max_score': 1.0,\n",
        "  u'total': 1},\n",
        " u'timed_out': False,\n",
        " u'took': 4}"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_fields = [\"feature_{0}\".format(i) for i in xrange(reduced_features.shape[1])]\n",
      "es.mlt(index='images', doc_type='features', search_size=6, mlt_fields=['feature_0'], min_term_freq=1, min_doc_freq=1, id=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "{u'_shards': {u'failed': 0, u'successful': 5, u'total': 5},\n",
        " u'hits': {u'hits': [], u'max_score': None, u'total': 0},\n",
        " u'timed_out': False,\n",
        " u'took': 3}"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}